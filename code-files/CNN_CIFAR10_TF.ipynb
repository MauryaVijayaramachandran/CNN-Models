{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Name : Maurya Vijayaramchandran \n",
        "\n",
        "Project : Building a convolutional Neural net on CIFAR10 dataset "
      ],
      "metadata": {
        "id": "cX1dqqk1T4e7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import the libraries"
      ],
      "metadata": {
        "id": "LBdJPjDaUIGr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJikJx1jrb7O"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.datasets import cifar10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the dataset and split it into test and train sets \n",
        "1. The test and train sets are further split into \n",
        "a. Features X_train , X_test\n",
        "b. Labels y_train, y_test"
      ],
      "metadata": {
        "id": "rjJL02jwUL2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test,y_test) = cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWZtwkgFsFZg",
        "outputId": "ffdbccca-f5af-4b87-ee65-a6d5a1152706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 19s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the shape of the dataset "
      ],
      "metadata": {
        "id": "o8xGG_hEUelV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype(\"float32\")/255.0\n",
        "x_test = x_test.astype(\"float32\")/255.0"
      ],
      "metadata": {
        "id": "K-SoyYK5sNf1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the model"
      ],
      "metadata": {
        "id": "YMWl8RRFHcIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Create a CNN model using Keras API of TensorFlow.\n",
        "\n",
        "Parameters:\n",
        "    None\n",
        "\n",
        "Returns:\n",
        "    keras.Sequential: A sequential model object.\n",
        "\n",
        "Architecture:\n",
        "    - Input layer: accepts 32x32 RGB images\n",
        "    - Conv2D layer with 32 filters of size (3,3), ReLU activation, and valid padding\n",
        "    - MaxPooling2D layer with pool size (2,2)\n",
        "    - Conv2D layer with 64 filters of size 3x3, ReLU activation, and default padding\n",
        "    - MaxPooling2D layer with default pool size (2,2)\n",
        "    - Conv2D layer with 128 filters of size 3x3, ReLU activation, and default padding\n",
        "    - Flatten layer to convert 2D features to 1D features\n",
        "    - Dense layer with 64 neurons and ReLU activation\n",
        "    - Dense output layer with 10 neurons for classification\n",
        "\n",
        "Note:\n",
        "    - The model is compiled on Colab with GPU.\n",
        "    - The output layer has no activation function, so it returns logits.\n",
        "\"\"\"\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(32,32,3)),\n",
        "     layers.Conv2D(32,(3,3), padding = \"valid\", activation = \"relu\"),\n",
        "     layers.MaxPooling2D(pool_size=(2,2)),\n",
        "     layers.Conv2D(64,3, activation = \"relu\"),\n",
        "     layers.MaxPooling2D(),\n",
        "     layers.Conv2D(128,3,activation = \"relu\"),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(64,activation = \"relu\"),\n",
        "     layers.Dense(10)\n",
        "\n",
        "    ]\n",
        ")\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivxuz7YLshhe",
        "outputId": "2aba296b-fbf5-4823-c695-257abd5734a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 30, 30, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 13, 13, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 6, 6, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)         73856     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                131136    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 225,034\n",
            "Trainable params: 225,034\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "compiling the model"
      ],
      "metadata": {
        "id": "Ef5-KQCQHuJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Compilation block\n",
        "\n",
        "Parameters:\n",
        "    loss: str or callable. The loss function to use. If a string, the name of the built-in Keras loss function. If a callable, the custom loss function to use. Default is SparseCategoricalCrossentropy from logits.\n",
        "    optimizer: str, callable, or tf.keras.optimizers.Optimizer object. The optimizer to use during training. If a string, the name of the built-in Keras optimizer. If a callable, the custom optimizer to use. Default is Adam with learning rate of 0.01.\n",
        "    metrics: list of str. The evaluation metrics to use during training and testing. If not provided, the default metric for each model will be used.\n",
        "\n",
        "Returns:\n",
        "    None\n",
        "\n",
        "Note:\n",
        "    - This method must be called before training the model.\n",
        "    - It is possible to pass custom metrics as a function or a list of functions.\n",
        "\"\"\"\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics = [\"accuracy\"],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "1WNisGFltzJn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "modifying the model as a functional model"
      ],
      "metadata": {
        "id": "FpGtYQ23HxvU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is overfitting, let us add regularization"
      ],
      "metadata": {
        "id": "ouY3wrkTxpaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def my_model():\n",
        "\"\"\"\n",
        "Define a custom Keras model.\n",
        "\n",
        "Returns:\n",
        "    A Keras model object.\n",
        "\n",
        "Note:\n",
        "    - This model consists of multiple convolutional layers, batch normalization, activation functions, max pooling, and dense layers.\n",
        "    - Regularization techniques such as L2 regularization and dropout are also used.\n",
        "    - This function returns the defined Keras model object.\n",
        "\"\"\"\n",
        "\n",
        "  inputs = keras.Input(shape= (32,32,3))\n",
        "  x = layers.Conv2D(32,3, padding = \"same\",\n",
        "                    kernel_regularizer = regularizers.l2(0.01)\n",
        "                    )(inputs)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.MaxPooling2D()(x)\n",
        "  x = layers.Conv2D(64,5,padding = \"same\",\n",
        "                    kernel_regularizer = regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Conv2D(128,3,padding = \"same\",\n",
        "                    kernel_regularizer = regularizers.l2(0.01))(x)\n",
        "  x = layers.BatchNormalization()(x)\n",
        "  x = keras.activations.relu(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation=\"relu\",kernel_regularizer = regularizers.l2(0.01))(x)\n",
        "  x = layers.Dropout(0.5)(x)\n",
        "  outputs = layers.Dense(10)(x)\n",
        "  model = keras.Model(inputs = inputs, outputs = outputs)\n",
        "  return model\n",
        "model = my_model()\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2YysM4uuZth",
        "outputId": "ebd1bf17-0c5f-407a-9147-157baa6d8e97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_16 (Conv2D)          (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " tf.nn.relu_13 (TFOpLambda)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_17 (Conv2D)          (None, 16, 16, 64)        51264     \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " tf.nn.relu_14 (TFOpLambda)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_18 (Conv2D)          (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " tf.nn.relu_15 (TFOpLambda)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                2097216   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                650       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,224,778\n",
            "Trainable params: 2,224,330\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the functional model"
      ],
      "metadata": {
        "id": "jovVX1k3WBO8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Compile block\n",
        "\n",
        "Parameters:\n",
        "    loss: str or callable. The loss function to use. If a string, the name of the built-in Keras loss function. If a callable, the custom loss function to use. Default is SparseCategoricalCrossentropy from logits.\n",
        "    optimizer: str, callable, or tf.keras.optimizers.Optimizer object. The optimizer to use during training. If a string, the name of the built-in Keras optimizer. If a callable, the custom optimizer to use. Default is Adam with learning rate of 0.01.\n",
        "    metrics: list of str. The evaluation metrics to use during training and testing. If not provided, the default metric for each model will be used.\n",
        "\n",
        "Returns:\n",
        "    None\n",
        "\n",
        "Note:\n",
        "    - This method must be called before training the model.\n",
        "    - It is possible to pass custom metrics as a function or a list of functions.\n",
        "\"\"\"\n",
        "\n",
        "model.compile(\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits= True),\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=0.01),\n",
        "    metrics = [\"accuracy\"],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "MP3DoS9kHNSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and testing the model."
      ],
      "metadata": {
        "id": "s9mYqKxZWDrz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train and evaluate a Keras model.\n",
        "\n",
        "Parameters:\n",
        "    x_train: array-like. The training data.\n",
        "    y_train: array-like. The training labels.\n",
        "    x_test: array-like. The testing data.\n",
        "    y_test: array-like. The testing labels.\n",
        "    batch_size: int. The number of samples per gradient update. Default is 64.\n",
        "    epochs: int. The number of times to iterate over the entire training dataset. Default is 150.\n",
        "    verbose: int. Verbosity mode (0 = silent, 1 = progress bar, 2 = one line per epoch). Default is 2.\n",
        "\n",
        "Returns:\n",
        "    A tuple of test loss and test accuracy values.\n",
        "\n",
        "Note:\n",
        "    - This method fits the Keras model on the training dataset and evaluates the trained model on the testing dataset.\n",
        "    - It is recommended to use a validation dataset to monitor the performance of the model during training.\n",
        "\"\"\"\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=64, epochs= 150, verbose = 2)\n",
        "model.evaluate(x_test,y_test, batch_size=32, verbose = 2)"
      ],
      "metadata": {
        "id": "yequfjT-HP-H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}